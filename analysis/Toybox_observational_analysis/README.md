*feature_prep.py*: contains a function feature_construction() that constructs the aggregate variables.  It takes as arguments the input file, desired outcome, and whether or not to save the resulting data as a csv.  This file could probably be broken down into sub-functions for better modularity, but for now, it should work.  Any new outcomes/aggregate variables that we want should be implemented in here.
*random_forest_analysis.py*: reads in either the output of feature_construction() or loads in a csv file, and does all the prep necessary to train and use the random forest model: discretizing predictors (for use in the covariate models), sub-sampling positive/negative data points, training the random forests, and generating explanations.  Down the road, once we're more settled on a model, we'd probably want to separate out the model training and the explanation generation.  However, for now, the model is constantly changing, and it really doesn't take long to train (especially compared w/feature construction), so I'm okay leaving it as one block for now.
